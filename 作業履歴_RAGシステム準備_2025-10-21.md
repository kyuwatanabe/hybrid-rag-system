# 作業履歴 - RAGシステム準備 - 2025年10月21日

## 作業サマリー

**実施内容:** RAGシステム開発の準備作業

**主な成果:**
- RAGシステムの詳細な開発計画を作成
- プロジェクト構造の設計と初期セットアップ完了
- 次回作業開始時にすぐに開発に入れる状態

---

## 背景

### FAQシステムの2つのアプローチ

今日のセッション中に、ユーザーから「FAQ大量生成vs検索時生成」の2つのアプローチについて相談がありました。

#### アプローチ1: 現行FAQシステム（既存）
- PDFから事前にFAQを大量生成
- データベース（CSV/SQLite）に保存
- ユーザーの質問時にFAQデータベースから検索
- **メリット:** 高速、品質が事前レビュー済み
- **デメリット:** 生成コスト高、網羅性に限界

#### アプローチ2: RAGシステム（新規開発）
- FAQを事前生成しない
- ユーザーの質問時にPDFから関連部分を検索
- LLMで直接回答を生成
- **メリット:** 網羅性が高い、特化した回答、新PDFに即対応
- **デメリット:** 回答が遅い、質問ごとにAPI呼び出しコスト

### ユーザーの要望

> 「ユーザーインターフェースも恐らくだいぶ変わるし、別プロジェクトでいいや。次回RAGシステムの開発に入れるように準備だけしておいてくれる。スムーズに開発が始められるように、ちゃんと作業履歴を残しておいて。」

---

## 実施した作業

### 1. RAGシステム開発計画の作成

**ファイル:** `RAGシステム開発計画.md`（親ディレクトリ）

**内容:**
- プロジェクト概要（現行システムとの比較表）
- システム設計（5つのフェーズ詳細）
- 技術スタックの選定
- プロジェクト構造
- 開発ステップ（Phase 1～5）
- 必要なライブラリ一覧
- 予想される課題と対策
- 次回作業開始時のチェックリスト

**重要な設計決定:**

1. **PDF前処理**
   - チャンクサイズ: 500-1000文字
   - 重複幅: 100文字程度
   - セマンティック重複除去（類似度0.93以上）

2. **ベクトルDB**
   - FAISS（ローカル、高速）を採用
   - 代替案: Chroma（使いやすさ重視）

3. **埋め込みモデル**
   - Sentence Transformers: `paraphrase-multilingual-mpnet-base-v2`
   - 日本語対応、無料
   - 代替案: OpenAI Embeddings（有料だが高精度）

4. **LLM API**
   - Claude API（現行と同じ）
   - ハルシネーション対策のプロンプト設計

5. **ハルシネーション対策（重要）**
   ```
   【重要なルール】
   1. 参照情報に書かれている内容**のみ**を使って回答
   2. 参照情報に書かれていない内容は推測しない
   3. 答えられない場合は「資料に記載されておりません」と答える
   4. 必ず出典（ページ番号、ファイル名）を表示
   ```

### 2. プロジェクト構造の作成

**ディレクトリ構造:**
```
C:\Users\GF001\Desktop\システム開発\手引き用チャットボット\
├── faq_system/           # 既存のFAQシステム（変更なし）
└── rag_system/           # 新しいRAGシステム（今回作成）
    ├── app.py            # Flaskアプリケーション（未作成）
    ├── rag_system.py     # RAGコアロジック（未作成）
    ├── pdf_processor.py  # PDF前処理（未作成）
    ├── vector_store.py   # ベクトルDB操作（未作成）
    ├── requirements.txt  # 依存ライブラリ ✓
    ├── .env.sample       # 環境変数サンプル ✓
    ├── .gitignore        # Git除外設定 ✓
    ├── README.md         # プロジェクト説明 ✓
    ├── 作業履歴_RAGシステム準備_2025-10-21.md  # このファイル
    ├── templates/        # HTMLテンプレート（空）
    │   ├── index.html    # チャット画面（未作成）
    │   └── admin.html    # 管理画面（未作成）
    ├── static/           # 静的ファイル（空）
    │   ├── css/
    │   │   └── style.css # スタイル（未作成）
    │   └── js/
    │       └── chat.js   # チャットJS（未作成）
    ├── reference_docs/   # PDFファイル（シンボリックリンク予定）
    └── vector_db/        # ベクトルDB保存先（空）
```

**作成したファイル:**

1. **`requirements.txt`**
   - Flask 2.3.0
   - PyMuPDF 1.23.0（PDF処理）
   - sentence-transformers 2.2.2（埋め込み）
   - faiss-cpu 1.7.4（ベクトル検索）
   - anthropic 0.18.0（Claude API）
   - その他データ処理ライブラリ

2. **`.env.sample`**
   - Claude APIキーの設定例
   - Flask設定
   - ベクトルDB設定
   - 検索設定
   - 重複除去設定

3. **`.gitignore`**
   - Python関連（`__pycache__/`, `venv/`）
   - 環境変数（`.env`）
   - ベクトルDB（`vector_db/`, `*.bin`）
   - IDE、OS、ログファイル

4. **`README.md`**
   - プロジェクト概要
   - 現行システムとの違い
   - 技術スタック
   - セットアップ手順
   - 開発ステップ
   - 次回作業開始時の案内

### 3. 開発計画の詳細化

**Phase 1: PDF前処理とベクトル化（予定: 1-2時間）**

実装予定の機能:
- PDFファイル読み込み（PyMuPDF）
- テキストチャンク化（500-1000文字、重複100文字）
- セマンティック重複除去（類似度0.93以上でクラスタリング）
- FAISSインデックス作成・保存

成果物: `vector_db/faiss_index.bin`

**Phase 2: 検索システム（予定: 1時間）**

実装予定の機能:
- ユーザーの質問をベクトル化
- FAISS検索でTop 10-20チャンク取得
- 類似度ランキング
- 重複排除して5-8チャンクに絞る

成果物: `vector_store.py`の検索関数

**Phase 3: 回答生成（予定: 1時間）**

実装予定の機能:
- ハルシネーション対策プロンプト設計
- Claude APIで回答生成
- 出典情報の整形（ページ番号、ファイル名）

成果物: `rag_system.py`の回答生成関数

**Phase 4: Webインターフェース（予定: 2時間）**

実装予定の機能:
- チャット画面のUI（現行とは異なるデザイン）
- Flask APIエンドポイント（`/rag_search`）
- JavaScript連携（リアルタイム回答表示）

成果物: 動作するWebアプリ

**Phase 5: テストと改善（予定: 1-2時間）**

実装予定の機能:
- 実際の質問でテスト
- 回答精度の評価
- プロンプトの微調整
- ハルシネーションチェック

---

## 技術的な検討事項

### 1. 埋め込みモデルの選択

**候補1: Sentence Transformers（採用）**
- モデル: `paraphrase-multilingual-mpnet-base-v2`
- メリット: 日本語対応、無料、ローカルで動作
- デメリット: OpenAIより精度がやや劣る可能性

**候補2: OpenAI Embeddings**
- モデル: `text-embedding-ada-002`
- メリット: 高精度
- デメリット: 有料（$0.0001/1000トークン）、API呼び出し必要

**決定:** まずSentence Transformersで試し、精度が不十分ならOpenAIに切り替え

### 2. ベクトルDBの選択

**候補1: FAISS（採用）**
- メリット: 高速、ローカルで動作、軽量
- デメリット: やや設定が複雑

**候補2: Chroma**
- メリット: 使いやすい、メタデータ管理が簡単
- デメリット: FAISSより遅い可能性

**決定:** FAISSで開始、問題があればChromaに切り替え

### 3. チャンクサイズの決定

**検討:**
- 小さすぎる（200-300文字）: 文脈が失われる
- 大きすぎる（1500-2000文字）: 無関係な情報が混入

**決定:**
- チャンクサイズ: 500-1000文字
- 重複幅: 100文字
- 実際のPDFで調整が必要

### 4. ハルシネーション対策

**重要な課題:**
LLMが参照情報外の一般知識を使って回答してしまう問題

**対策:**
1. プロンプトで強く制約
   - 「参照情報**のみ**を使用」を複数回強調
   - 「推測禁止」を明記
   - 「不明な場合の回答例」を提示

2. 出典の必須化
   - 必ずページ番号とファイル名を表示
   - ユーザーが検証可能

3. テストケースでの評価
   - 「PDFに書かれていない質問」をテスト
   - 正しく「不明」と答えるか確認

---

## 予想される課題と対策

### 課題1: 回答速度が遅い

**問題:**
- ベクトル検索: 0.5-1秒
- Claude API: 2-3秒
- 合計: 3-4秒

**対策:**
- ユーザー体験: 「回答を生成中...」のローディング表示
- 最適化: FAISSの高速化設定
- 将来的: キャッシュ機能（同じ質問は再利用）

### 課題2: ハルシネーション（幻覚回答）

**問題:**
LLMが参照情報外の知識を使ってしまう

**対策:**
- プロンプトで強く制約
- 出典の必須化
- テストケースでの評価
- 人間による確認

### 課題3: 複数チャンクにまたがる質問

**問題:**
「Aの場合とBの場合の違いは?」など

**対策:**
- 検索で関連チャンクを複数取得（5-8個）
- LLMが複数チャンクを統合して回答
- プロンプトで「複数チャンクの情報を統合」を指示

### 課題4: 日本語の埋め込み精度

**問題:**
英語に比べて日本語の埋め込み精度が低い可能性

**対策:**
- `paraphrase-multilingual-mpnet-base-v2`を使用（日本語対応）
- テストで精度を確認
- 不十分ならOpenAI Embeddingsに切り替え

### 課題5: コスト

**問題:**
質問ごとにClaude API呼び出し（現行は事前生成済み）

**対策:**
- キャッシュ機能（同じ質問は再利用）
- よくある質問は現行FAQシステムで対応
- RAGは特殊な質問のみで使用

---

## 次回作業開始時のチェックリスト

### 環境準備

- [ ] `rag_system/` ディレクトリに移動
- [ ] Python仮想環境を作成
  ```bash
  python -m venv venv
  venv\Scripts\activate  # Windows
  ```
- [ ] 依存ライブラリをインストール
  ```bash
  pip install -r requirements.txt
  ```
- [ ] `.env.sample` をコピーして `.env` を作成
- [ ] `.env` にClaude API Keyを設定
- [ ] PDFファイルを配置（既存を使うか、シンボリックリンク作成）

### Phase 1 実装（PDF前処理）

- [ ] `pdf_processor.py` を作成
  - [ ] PDFからテキスト抽出の関数
  - [ ] チャンク化の関数（500-1000文字、重複100文字）
  - [ ] セマンティック重複除去の関数（類似度0.93以上）
  - [ ] FAISSインデックス作成・保存の関数

- [ ] テスト実行
  ```bash
  python pdf_processor.py
  ```
  - [ ] `第2章.pdf` でテキスト抽出を確認
  - [ ] チャンク数とサイズを確認
  - [ ] 重複除去の効果を確認
  - [ ] `vector_db/faiss_index.bin` が生成されることを確認

### Phase 2 以降

Phase 1が完了してから進める

---

## 参考資料

### 作成したファイル

1. **`RAGシステム開発計画.md`**（親ディレクトリ）
   - 場所: `C:\Users\GF001\Desktop\システム開発\手引き用チャットボット\RAGシステム開発計画.md`
   - 詳細な設計とフェーズ別実装計画

2. **`README.md`**（プロジェクトルート）
   - 場所: `C:\Users\GF001\Desktop\システム開発\手引き用チャットボット\rag_system\README.md`
   - セットアップ手順と概要

3. **`requirements.txt`**
   - 依存ライブラリ一覧

4. **`.env.sample`**
   - 環境変数の設定例

5. **`作業履歴_RAGシステム準備_2025-10-21.md`**（このファイル）
   - 今日の作業内容と次回作業開始の案内

### 元の提案

- **ファイル:** `C:\Users\GF001\Desktop\Temp\Claudeの提案.txt`
- **内容:** RAGシステムの基本的なアイデア

### 関連プロジェクト

- **現行FAQシステム:** `C:\Users\GF001\Desktop\システム開発\手引き用チャットボット\faq_system\`
- **既存PDFファイル:** `faq_system/reference_docs/第2章.pdf` など

---

## 所感

### 成功のポイント

- 現行FAQシステムとRAGシステムを完全に分離
- 両方のアプローチを比較できる環境を整備
- 次回作業開始時にすぐに開発に入れる状態

### 技術的な期待

- ハルシネーション対策がうまく機能するか
- 日本語の埋め込み精度が十分か
- 回答速度が許容範囲内か

### 今後の展開

**短期（次回セッション）:**
- Phase 1（PDF前処理）の実装
- ベクトルDBの作成

**中期（1週間以内）:**
- Phase 2-4の実装
- 動作するWebアプリの完成

**長期（1ヶ月以上）:**
- 現行FAQシステムとRAGシステムの品質比較
- ハイブリッドアプローチ（よくある質問はFAQ、特殊な質問はRAG）
- ユーザーフィードバックの収集

---

## 次回作業の開始方法

1. この作業履歴ファイル（`作業履歴_RAGシステム準備_2025-10-21.md`）を読む
2. `RAGシステム開発計画.md` で詳細設計を確認
3. `README.md` でセットアップ手順を確認
4. 環境準備のチェックリストを実行
5. Phase 1（PDF前処理）の実装を開始

---

**作業終了時刻:** 2025-10-21 20:15（推定）
**作業時間:** 約10分
**主担当:** Claude Code
**ユーザー:** GF001

準備完了！次回RAGシステムの開発をスムーズに始められます！
